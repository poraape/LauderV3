# FILE: app.py
import gradio as gr
from main_orchestrator import OrquestradorDiferencial
from rag.rag_service import RAGService
from rag.knowledge_base_content import get_knowledge_chunks
import time
import os

# --- L√ìGICA DE AUTOINICIALIZA√á√ÉO PARA DEPLOYMENT ---
# Esta se√ß√£o garante que a aplica√ß√£o possa se configurar sozinha na nuvem.

def setup_knowledge_base():
    """
    Verifica se a base de conhecimento existe e, se n√£o, a cria.
    """
    db_path = "chroma_db"
    # A verifica√ß√£o √© simples: a pasta existe?
    if not os.path.exists(db_path):
        print("INFO: Base de conhecimento n√£o encontrada. Iniciando processo de cria√ß√£o...")
        print("INFO: Este processo s√≥ ocorrer√° na primeira inicializa√ß√£o do Space.")
        
        # Pega os trechos de conhecimento
        chunks = get_knowledge_chunks()
        if not chunks:
            print("ERRO FATAL: Nenhum trecho de conhecimento encontrado para popular o banco de dados.")
            return

        # Instancia o servi√ßo RAG e popula a base
        rag_service = RAGService()
        rag_service.populate_knowledge_base(chunks)
        
        print("INFO: Base de conhecimento criada com sucesso.")
    else:
        print(f"INFO: Base de conhecimento encontrada em '{db_path}'. Inicializa√ß√£o normal.")

# Executa a verifica√ß√£o e o setup no momento em que a aplica√ß√£o √© iniciada
setup_knowledge_base()
# --- FIM DA L√ìGICA DE AUTOINICIALIZA√á√ÉO ---


# --- INICIALIZA√á√ÉO DO ORQUESTRADOR E DA INTERFACE ---
print("INFO: Inicializando o Orquestrador Diferencial...")
orquestrador = OrquestradorDiferencial()
print("INFO: Aplica√ß√£o Gradio pronta para ser lan√ßada.")


def stream_response(message: str, history: list, file_path: str | None):
    """
    Fun√ß√£o de streaming para a interface de chat.
    """
    print(f"INFO: Nova requisi√ß√£o recebida. Mensagem: '{message[:50]}...'. Arquivo: {file_path}")
    
    resultado_completo = orquestrador.executar_fluxo(message, file_path)
    
    buffer = ""
    for char in resultado_completo:
        buffer += char
        yield buffer
        time.sleep(0.01)

# Interface Gradio (sem mudan√ßas na UI)
with gr.Blocks(theme=gr.themes.Default(primary_hue="sky"), css=".gradio-container {max-width: 960px !important; margin: auto;}") as demo:
    gr.Markdown(
        """
        <div style="text-align: center;">
            <h1>ü©∫ LauderExam‚Ñ¢ v3</h1>
            <p><strong>The Differential Engine</strong>: An√°lise Cl√≠nica Multimodal com Racioc√≠nio Paralelo</p>
        </div>
        """
    )
    
    gr.ChatInterface(
        fn=stream_response,
        chatbot=gr.Chatbot(height=600, show_copy_button=True, bubble_full_width=False),
        textbox=gr.Textbox(placeholder="Descreva o caso cl√≠nico aqui...", container=False, scale=7),
        additional_inputs=[gr.File(label="Upload de Imagem ou Documento (Opcional)", type="filepath")],
        submit_btn="Analisar Caso",
        retry_btn="Tentar Novamente",
        undo_btn="Desfazer",
        clear_btn="Limpar Chat",
        title=None,
        examples=[
            ["Paciente com dispneia s√∫bita e dor no peito h√° 1 dia. D-d√≠mero elevado."],
            ["Homem, 65 anos, com febre alta e tosse produtiva h√° 3 dias. Leuc√≥citos aumentados."],
        ]
    )
    
    gr.Markdown(
        """
        <div style="text-align: center; font-size: small; color: grey;">
            <p>Aviso: Este √© um sistema de IA para fins de demonstra√ß√£o e n√£o substitui uma avalia√ß√£o m√©dica profissional.</p>
        </div>
        """
    )

# O Gradio no Hugging Face Spaces procura por uma vari√°vel chamada 'demo' para lan√ßar.
# N√£o precisamos mais do bloco if __name__ == "__main__": demo.launch()
